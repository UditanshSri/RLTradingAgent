{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-02-03T13:19:45.109845Z","iopub.execute_input":"2025-02-03T13:19:45.110079Z","iopub.status.idle":"2025-02-03T13:19:46.736798Z","shell.execute_reply.started":"2025-02-03T13:19:45.110056Z","shell.execute_reply":"2025-02-03T13:19:46.735831Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:19:46.737833Z","iopub.execute_input":"2025-02-03T13:19:46.738354Z","iopub.status.idle":"2025-02-03T13:19:49.010728Z","shell.execute_reply.started":"2025-02-03T13:19:46.738328Z","shell.execute_reply":"2025-02-03T13:19:49.009707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"! wget \"https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL/refs/heads/master/requirements.txt\"\n! sudo apt-get install swig\n! pip install box2d-py\n! pip install -r requirements.txt\n! pip install finrl yfinance stable_baselines3","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:19:49.011661Z","iopub.execute_input":"2025-02-03T13:19:49.012181Z","iopub.status.idle":"2025-02-03T13:24:05.353131Z","shell.execute_reply.started":"2025-02-03T13:19:49.012127Z","shell.execute_reply":"2025-02-03T13:24:05.351780Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n\nticker = \"GOOGL\"\nbenchmark_ticker = \"^GSPC\" # S&P 500\nstart_date = \"2015-01-01\"\nend_date = \"2025-01-01\"\n\ndf_stock = YahooDownloader(start_date=start_date, end_date=end_date, ticker_list=[ticker]).fetch_data()\ndf_benchmark = YahooDownloader(start_date=start_date, end_date=end_date, ticker_list=[benchmark_ticker]).fetch_data()\n\ndf = pd.merge(df_stock, df_benchmark[['date', 'close']], on='date', suffixes=('', '_benchmark'))\n\ndf","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:24:05.356472Z","iopub.execute_input":"2025-02-03T13:24:05.356802Z","iopub.status.idle":"2025-02-03T13:24:34.394621Z","shell.execute_reply.started":"2025-02-03T13:24:05.356775Z","shell.execute_reply":"2025-02-03T13:24:34.393560Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot stock closing price over time\n%matplotlib inline\nplt.figure(figsize=(12, 6))\nsns.lineplot(x=pd.to_datetime(df['date']), y=df[\"close\"], label=\"Closing Price\", color=\"blue\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Stock Price (USD)\")\nplt.title(f\"{ticker} Closing Stock Over Time\")\nplt.xticks(rotation=45)\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:24:34.396597Z","iopub.execute_input":"2025-02-03T13:24:34.397280Z","iopub.status.idle":"2025-02-03T13:24:34.928852Z","shell.execute_reply.started":"2025-02-03T13:24:34.397250Z","shell.execute_reply":"2025-02-03T13:24:34.927887Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot benchmark data over time\n%matplotlib inline\nplt.figure(figsize=(12, 6))\nsns.lineplot(x=pd.to_datetime(df['date']), y=df[\"close_benchmark\"], label=\"Closing Price Benchmark\", color=\"green\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Stock Price (USD)\")\nplt.title(f\"{benchmark_ticker} Over Time\")\nplt.xticks(rotation=45)\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:24:34.929814Z","iopub.execute_input":"2025-02-03T13:24:34.930082Z","iopub.status.idle":"2025-02-03T13:24:35.298566Z","shell.execute_reply.started":"2025-02-03T13:24:34.930060Z","shell.execute_reply":"2025-02-03T13:24:35.297593Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from finrl.config import INDICATORS\nfrom finrl.meta.preprocessor.preprocessors import FeatureEngineer\n\nfe = FeatureEngineer(\n    use_technical_indicator=True, \n    tech_indicator_list=INDICATORS,\n    use_turbulence=True\n)\ndf = fe.preprocess_data(df)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:24:35.299605Z","iopub.execute_input":"2025-02-03T13:24:35.299983Z","iopub.status.idle":"2025-02-03T13:24:42.480250Z","shell.execute_reply.started":"2025-02-03T13:24:35.299949Z","shell.execute_reply":"2025-02-03T13:24:42.479076Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n\nclass CustomStockTradingEnv(StockTradingEnv):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.reward_function = None\n\n    def set_reward_function(self, reward_function):\n        self.reward_function = reward_function\n\n    def step(self, actions):\n        next_state, reward, terminal, truncated, info = super().step(actions)\n\n        if self.reward_function is not None:\n            reward = self.reward_function(self, actions, next_state, reward, terminal, truncated, info)\n        \n        return next_state, reward, terminal, truncated, info\n\nprint(\"Loaded class CustomStockTradingEnv\")","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:26:16.801762Z","iopub.execute_input":"2025-02-03T13:26:16.802173Z","iopub.status.idle":"2025-02-03T13:26:16.809073Z","shell.execute_reply.started":"2025-02-03T13:26:16.802122Z","shell.execute_reply":"2025-02-03T13:26:16.808020Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reward_logging = False  # set to True to print values\noverall_reward = 0  # set to 0 to get total accumulated reward\n\ndef sample_custom_reward(self, actions, next_state, base_reward, terminal, truncated, info):\n    import numpy as np\n    import pandas as pd\n    \n    # Convert memory to DataFrame\n    df_total_value = pd.DataFrame(self.asset_memory, columns=[\"account_value\"])\n    df_total_value[\"date\"] = self.date_memory\n    df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(1)\n    \n    # Get benchmark values from the 'close_benchmark' column, but only for rows up to the length of asset_memory\n    df_total_value[\"benchmark_value\"] = self.df[\"close_benchmark\"].iloc[:len(df_total_value)].reset_index(drop=True)\n    df_total_value[\"benchmark_daily_return\"] = df_total_value[\"benchmark_value\"].pct_change(1)\n    \n    # Remove NaN values\n    remove_nan = lambda x: 0 if np.isnan(x) else x\n    \n    # Calculate portfolio returns and risks\n    mean_returns = df_total_value[\"daily_return\"].mean()\n    std_returns = df_total_value[\"daily_return\"].std()\n    \n    # Calculate benchmark returns and risks\n    bench_returns = df_total_value[\"benchmark_daily_return\"].mean()\n    bench_std = df_total_value[\"benchmark_daily_return\"].std()\n    \n    # Calculate beta\n    beta = 1.0  # default value\n    if bench_std and not np.isnan(bench_std) and bench_std != 0:\n        portfolio_returns = df_total_value[\"daily_return\"].fillna(0)\n        benchmark_returns = df_total_value[\"benchmark_daily_return\"].fillna(0)\n        if len(portfolio_returns) == len(benchmark_returns):\n            covariance = np.cov(portfolio_returns, benchmark_returns)[0][1]\n            beta = covariance / (bench_std ** 2)\n    \n    # Compute Sharpe Ratio\n    sharpe = 0\n    if std_returns and not np.isnan(std_returns):\n        sharpe = (252**0.5) * mean_returns / std_returns\n    \n    # Compute Sortino Ratio\n    downside_returns = df_total_value[\"daily_return\"][df_total_value[\"daily_return\"] < 0]\n    downside_std = downside_returns.std(ddof=1)\n    \n    sortino = 0\n    if downside_std and not np.isnan(downside_std):\n        sortino = (252**0.5) * mean_returns / downside_std\n    \n    # Compute Treynor Ratio\n    treynor = 0\n    if beta and not np.isnan(beta) and beta != 0:\n        treynor = (252**0.5) * mean_returns / beta\n    \n    # Compute Differential Return\n    diff_return = 0\n    if beta and not np.isnan(beta) and beta != 0:\n        diff_return = (mean_returns - bench_returns) / beta\n    \n    if reward_logging:\n        print(f\"Mean Daily Returns: {mean_returns}\")\n        print(f\"Benchmark Returns: {bench_returns}\")\n        print(f\"Daily Return Standard Deviation: {std_returns}\")\n        print(f\"Downside Only Standard Deviation: {downside_std}\")\n        print(f\"Beta: {beta}\")\n        print(f\"Sharpe Ratio: {sharpe}\")\n        print(f\"Sortino Ratio: {sortino}\")\n        print(f\"Treynor Ratio: {treynor}\")\n        print(f\"Differential Return: {diff_return}\")\n    \n    # Compute final reward with all components\n    total_reward = (\n        (252**0.5) * remove_nan(mean_returns) \n        - remove_nan(abs(downside_std)) \n        + remove_nan(treynor) \n        + remove_nan(diff_return)\n    )\n    \n    if reward_logging:\n        print(f\"Reward: {total_reward}\")\n        print(\"-----------------------------\")\n    \n    global overall_reward\n    overall_reward += total_reward\n    \n    return total_reward\n\nprint(\"Loaded custom reward function\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:07:44.393268Z","iopub.execute_input":"2025-02-03T14:07:44.393604Z","iopub.status.idle":"2025-02-03T14:07:44.406627Z","shell.execute_reply.started":"2025-02-03T14:07:44.393577Z","shell.execute_reply":"2025-02-03T14:07:44.405637Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"indicators = [\"volume\",\t\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\", \"dx_30\", \"close_30_sma\", \"close_60_sma\", \"turbulence\"]\nturbulence_thresold=100\n\nstock_dim = len(df[\"tic\"].unique())\nmax_price = df['close'].max()\ninitial_amount = 10000\nhmax = int(initial_amount / max_price)\n\nenv = CustomStockTradingEnv(\n    df=df, \n    stock_dim=stock_dim, \n    hmax=hmax,\n    initial_amount=initial_amount, \n    num_stock_shares=[0],\n    print_verbosity=2,\n    buy_cost_pct=[0.001],\n    sell_cost_pct=[0.001],\n    turbulence_threshold=turbulence_thresold,\n    reward_scaling=1e-4,\n    tech_indicator_list=indicators,\n    state_space=1 + 2 * stock_dim + len(indicators) * stock_dim,\n    action_space=stock_dim,\n)\n\nenv","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:07:48.123548Z","iopub.execute_input":"2025-02-03T14:07:48.123837Z","iopub.status.idle":"2025-02-03T14:07:48.134368Z","shell.execute_reply.started":"2025-02-03T14:07:48.123816Z","shell.execute_reply":"2025-02-03T14:07:48.133436Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing the enviroment and set custom reward function\nenv.reset()\nreward_logging = True\nenv.set_reward_function(sample_custom_reward)\n\nenv.step(np.array([5]))\nenv.step(np.array([-5]))\nenv.step(np.array([0]))\nenv.step(np.array([0]))\nenv.step(np.array([0]))\nreward_logging = False","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:07:52.092766Z","iopub.execute_input":"2025-02-03T14:07:52.093079Z","iopub.status.idle":"2025-02-03T14:07:52.131870Z","shell.execute_reply.started":"2025-02-03T14:07:52.093056Z","shell.execute_reply":"2025-02-03T14:07:52.130973Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nenv.reset()\nvec_env = make_vec_env(lambda: env, n_envs=1)\n\nmodel = PPO(\"MlpPolicy\", vec_env, verbose=1)\nmodel.learn(total_timesteps=100000) ","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:08:30.591259Z","iopub.execute_input":"2025-02-03T14:08:30.591590Z","iopub.status.idle":"2025-02-03T14:20:10.595670Z","shell.execute_reply.started":"2025-02-03T14:08:30.591567Z","shell.execute_reply":"2025-02-03T14:20:10.594864Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"obs = vec_env.reset()\nvec_env.envs[0].unwrapped.episode = 0 # Prints episode info\noverall_reward = 0 # Keep track of accumulated overall reward\n\nportfolio_values = []\ntimesteps = []\n\ni = 0\nwhile True:\n    action, _states = model.predict(obs, deterministic=True)\n    obs, rewards, done, info = vec_env.step(action)\n\n    if done[0]:\n        break\n\n    portfolio_value = vec_env.envs[0].unwrapped.asset_memory[-1]\n    portfolio_values.append(portfolio_value)\n    timesteps.append(i)\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:21:25.356649Z","iopub.execute_input":"2025-02-03T14:21:25.356982Z","iopub.status.idle":"2025-02-03T14:21:39.737054Z","shell.execute_reply.started":"2025-02-03T14:21:25.356958Z","shell.execute_reply":"2025-02-03T14:21:39.736001Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(timesteps, portfolio_values, label=\"Portfolio Value\", color='blue')\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Portfolio Value ($)\")\nplt.title(\"RL Model Performance\")\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-02-03T14:21:54.665649Z","iopub.execute_input":"2025-02-03T14:21:54.665991Z","iopub.status.idle":"2025-02-03T14:21:54.903625Z","shell.execute_reply.started":"2025-02-03T14:21:54.665962Z","shell.execute_reply":"2025-02-03T14:21:54.902685Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(input())","metadata":{"execution":{"iopub.status.busy":"2025-02-03T13:24:42.780079Z","iopub.status.idle":"2025-02-03T13:24:42.780459Z","shell.execute_reply":"2025-02-03T13:24:42.780327Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}